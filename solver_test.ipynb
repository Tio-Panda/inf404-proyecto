{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d752f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import time\n",
    "from typing import Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "CNF_DIR = Path(\"./sym_data/cnf/test\")\n",
    "BACKBONE_DIR = Path(\"./sym_data/backbone/test\")\n",
    "SOLVER_BINARY = Path(\"./solver/build/kissat\")\n",
    "RESULTS_DIR = Path(\"./results\")\n",
    "\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "COMP_EXTS = [\".xz\", \".bz2\", \".gz\", \".lzma\"]\n",
    "\n",
    "\n",
    "TAKE_FRACTION: float = 0.6\n",
    "\n",
    "def remove_compression_suffix(filename: str) -> str:\n",
    "    \"\"\"Strip only the compression extension if present (xz, bz2, gz, lzma).\"\"\"\n",
    "    for ext in COMP_EXTS:\n",
    "        if filename.endswith(ext):\n",
    "            return filename[: -len(ext)]\n",
    "    return filename\n",
    "\n",
    "\n",
    "def is_cnf_like(name: str) -> bool:\n",
    "    \"\"\"Heuristic to select CNF-like instances in the dataset dirs.\n",
    "\n",
    "    We include files whose names contain any of these markers:\n",
    "    - '.cnf' (typical DIMACS CNF)\n",
    "    - '_cnf' (mcc2020 naming)\n",
    "    - 'dimacs' (some benchmarks use '.dimacs')\n",
    "    \"\"\"\n",
    "    lname = name.lower()\n",
    "    return (\".cnf\" in lname) or (\"_cnf\" in lname) or (\"dimacs\" in lname)\n",
    "\n",
    "\n",
    "def decompress_file(src_file: Path, dest_dir: Path, overwrite: bool = False) -> Path:\n",
    "    \"\"\"Decompress src_file if it's compressed into dest_dir and return the decompressed path.\n",
    "\n",
    "    The output filename is the source name with only the final compression suffix removed.\n",
    "    For example:\n",
    "      - 'foo.cnf.xz'   -> 'dest_dir/foo.cnf'\n",
    "      - 'bar.b+e.gz'   -> 'dest_dir/bar.b+e'\n",
    "      - 'baz.lzma'     -> 'dest_dir/baz'\n",
    "    If the file is not compressed, it is simply copied into dest_dir and that path is returned.\n",
    "    \"\"\"\n",
    "    dest_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    name_wo_comp = remove_compression_suffix(src_file.name)\n",
    "    out_path = dest_dir / name_wo_comp\n",
    "\n",
    "    if out_path.exists() and not overwrite:\n",
    "        return out_path\n",
    "\n",
    "    # Work on a temporary copy in destination directory to avoid modifying the source files\n",
    "    temp_src = dest_dir / src_file.name\n",
    "    shutil.copy(src_file, temp_src)\n",
    "\n",
    "    print(f\"Decompressing {src_file.name} into {out_path}...\")\n",
    "\n",
    "    if temp_src.suffix == \".xz\" or temp_src.suffix == \".lzma\":\n",
    "        # xz can decompress both .xz and .lzma\n",
    "        subprocess.run([\"xz\", \"-dkf\", str(temp_src)], check=True)\n",
    "    elif temp_src.suffix == \".bz2\":\n",
    "        subprocess.run([\"bzip2\", \"-dkf\", str(temp_src)], check=True)\n",
    "    elif temp_src.suffix == \".gz\":\n",
    "        subprocess.run([\"gzip\", \"-dkf\", str(temp_src)], check=True)\n",
    "    else:\n",
    "        # Not a recognized compression, just copy as-is\n",
    "        shutil.move(str(temp_src), str(out_path))\n",
    "        return out_path\n",
    "\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def run_cmd(cmd: List[str]) -> Tuple[str, float]:\n",
    "    start = time.time()\n",
    "    try:\n",
    "        result = subprocess.run(cmd, text=True, capture_output=True, timeout=10)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return \"TIMEOUT\", time.time() - start\n",
    "    elapsed = time.time() - start\n",
    "    stdout = result.stdout.strip() if result.stdout else \"NO_OUTPUT\"\n",
    "    return stdout, elapsed\n",
    "\n",
    "def build_cmd_default(cnf_path: Path) -> List[str]:\n",
    "    return [str(SOLVER_BINARY.resolve()), \"-q\", \"-n\", \"--stable=2\", str(cnf_path.resolve())]\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Collect CNF-like files, including compressed variants\n",
    "    candidate_files = [p for p in CNF_DIR.iterdir() if p.is_file() and is_cnf_like(p.name)]\n",
    "    cnf_files = sorted(candidate_files, key=lambda p: p.name)\n",
    "\n",
    "    # Apply subset selection for faster testing\n",
    "    if 0 < TAKE_FRACTION < 1.0 and cnf_files:\n",
    "        limit = max(1, int(len(cnf_files) * TAKE_FRACTION))\n",
    "        cnf_files = cnf_files[:limit]\n",
    "        print(f\"Using a subset: {limit}/{len(candidate_files)} instances.\")\n",
    "    summary = {\n",
    "        \"NeuroBack-Initial\": [],\n",
    "        \"NeuroBack-Weighted\": [],\n",
    "        \"NeuroBack-LowScores\": [],\n",
    "        \"NeuroBack-Always\": [],\n",
    "        \"Default\": []\n",
    "    }\n",
    "\n",
    "    for cnf_file in cnf_files:\n",
    "        print(f\"\\n=== Processing {cnf_file.name} ===\")\n",
    "\n",
    "        # Prepare a working directory under results for this instance\n",
    "        instance_key = remove_compression_suffix(cnf_file.name)  \n",
    "        cnf_result_dir = RESULTS_DIR / Path(instance_key).stem \n",
    "        cnf_result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Ensure we have an uncompressed CNF path to give the solver\n",
    "        cnf_path_for_solver = decompress_file(cnf_file, cnf_result_dir)\n",
    "\n",
    "        # Backbone path\n",
    "        backbone_xz = BACKBONE_DIR / f\"{cnf_file.stem}.backbone.xz\"\n",
    "        backbone_file = None\n",
    "        if backbone_xz.exists():\n",
    "            backbone_file = decompress_file(backbone_xz, cnf_result_dir)\n",
    "\n",
    "        # NeuroBack-Always\n",
    "        print(\"Running NeuroBack-Always...\")\n",
    "        if backbone_file:\n",
    "            na_out, na_time = run_cmd([\n",
    "                str(SOLVER_BINARY.resolve()), str(cnf_path_for_solver.resolve()), \"-q\", \"-n\",\n",
    "                \"--stable=2\", \"--neural_backbone_always\",\n",
    "                f\"--backbonefile={backbone_file.resolve()}\",\n",
    "            ])\n",
    "            summary[\"NeuroBack-Always\"].append((cnf_file.name, na_out, na_time))\n",
    "            \n",
    "        else:\n",
    "            summary[\"NeuroBack-Always\"].append((cnf_file.name, \"NO_BACKBONE\", 0.0))\n",
    "\n",
    "\n",
    "        # NeuroBack-Initial \n",
    "        print(\"Running NeuroBack-Initial...\")\n",
    "        if backbone_file:\n",
    "            nb_out, nb_time = run_cmd([\n",
    "                str(SOLVER_BINARY.resolve()), str(cnf_path_for_solver.resolve()), \"-q\", \"-n\",\n",
    "                \"--stable=2\", \"--neural_backbone_initial\", \"--neuroback_cfd=0.9\",\n",
    "                f\"--backbonefile={backbone_file.resolve()}\",\n",
    "            ])\n",
    "            summary[\"NeuroBack-Initial\"].append((cnf_file.name, nb_out, nb_time))\n",
    "            \n",
    "        else:\n",
    "            summary[\"NeuroBack-Initial\"].append((cnf_file.name, \"NO_BACKBONE\", 0.8))\n",
    "\n",
    "\n",
    "        # NeuroBack-Weighted \n",
    "        print(\"Running NeuroBack-Weighted...\")\n",
    "        if backbone_file:\n",
    "            bw_out, bw_time = run_cmd([\n",
    "                str(SOLVER_BINARY.resolve()), str(cnf_path_for_solver.resolve()), \"-q\", \"-n\",\n",
    "                \"--stable=2\", \"--neural_backbone_weighted\", \"--neural_backbone_weight=0.7\",\n",
    "                f\"--backbonefile={backbone_file.resolve()}\",\n",
    "            ])\n",
    "            summary[\"NeuroBack-Weighted\"].append((cnf_file.name, bw_out, bw_time))\n",
    "            \n",
    "        else:\n",
    "            summary[\"NeuroBack-Weighted\"].append((cnf_file.name, \"NO_BACKBONE\", 0.7))\n",
    "        \n",
    "\n",
    "        # NeuroBack-LowScores\n",
    "        print(\"Running NeuroBack-LowScores...\")\n",
    "        if backbone_file:\n",
    "            ls_out, ls_time = run_cmd([\n",
    "                str(SOLVER_BINARY.resolve()), str(cnf_path_for_solver.resolve()), \"-q\", \"-n\",\n",
    "                \"--stable=2\", \"--neural_backbone_lowscores\", \"--lowscores_threshold=0.1\",\n",
    "                f\"--backbonefile={backbone_file.resolve()}\",\n",
    "            ])\n",
    "            summary[\"NeuroBack-LowScores\"].append((cnf_file.name, ls_out, ls_time))\n",
    "            \n",
    "        else:\n",
    "            summary[\"NeuroBack-LowScores\"].append((cnf_file.name, \"NO_BACKBONE\", 0.0))\n",
    "\n",
    "        # Default-Kissat\n",
    "        print(\"Running Default-Kissat...\")\n",
    "        def_out, def_time = run_cmd(build_cmd_default(cnf_path_for_solver))\n",
    "        summary[\"Default\"].append((cnf_file.name, def_out, def_time))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    # --- PRINT SUMMARY ---\n",
    "    for config in [\"NeuroBack-Always\",\"NeuroBack-Initial\", \"NeuroBack-Weighted\", \"NeuroBack-LowScores\", \"Default\"]:\n",
    "        print(f\"\\n===== RESULTS FOR {config} =====\")\n",
    "        total_time = 0\n",
    "        sat_count = unsat_count = error_count = no_backbone = 0\n",
    "\n",
    "        for cnf_name, result, t in summary[config]:\n",
    "            total_time += t\n",
    "\n",
    "            if \"SATISFIABLE\" in result:\n",
    "                sat_count += 1\n",
    "            elif \"UNSATISFIABLE\" in result:\n",
    "                unsat_count += 1\n",
    "            elif result == \"NO_BACKBONE\":\n",
    "                no_backbone += 1\n",
    "            elif result in (\"TIMEOUT\", \"NO_OUTPUT\"):\n",
    "                error_count += 1\n",
    "            else:\n",
    "                # Clasifica cualquier salida no reconocida como error para cerrar la suma\n",
    "                error_count += 1\n",
    "\n",
    "        print(f\"\\n--- METRICS ({config}) ---\")\n",
    "        print(f\"Total problems: {len(cnf_files)}\")\n",
    "        print(f\"SAT: {sat_count}\")\n",
    "        print(f\"UNSAT: {unsat_count}\")\n",
    "        print(f\"Errors: {error_count}\")\n",
    "        print(f\"No Backbone: {no_backbone}\")\n",
    "        print(f\"Total solving time: {total_time:.4f}s\")\n",
    "        avg = (total_time / len(cnf_files)) if cnf_files else 0.0\n",
    "        print(f\"Average per problem: {avg:.4f}s\")\n",
    "        variance = sum((t - avg) ** 2 for _, _, t in summary[config]) / len(cnf_files) if cnf_files else 0.0\n",
    "        print(f\"Time variance: {variance:.4f}s^2\")\n",
    "\n",
    "    # Generate cactus plot at the end\n",
    "    plot_cactus(summary)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_cactus(summary: dict):\n",
    "    \"\"\"Generate a cactus plot comparing methods by sorted runtimes of solved instances.\n",
    "\n",
    "    For each configuration, we take the runtimes of instances classified as SAT or UNSAT,\n",
    "    sort them ascending, and plot runtime vs. instance index (1..N solved).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    configs = [\n",
    "        \"NeuroBack-Always\",\n",
    "        \"NeuroBack-Initial\",\n",
    "        \"NeuroBack-Weighted\",\n",
    "        \"NeuroBack-LowScores\",\n",
    "        \"Default\",\n",
    "    ]\n",
    "    for config in configs:\n",
    "        entries = summary.get(config, [])\n",
    "        solved_times = [t for _, result, t in entries if (\"SATISFIABLE\" in result) or (\"UNSATISFIABLE\" in result)]\n",
    "        solved_times.sort()\n",
    "        if not solved_times:\n",
    "            continue\n",
    "        x = list(range(1, len(solved_times) + 1))\n",
    "        plt.plot(x, solved_times, marker='o', linestyle='-', label=f\"{config} (solved={len(solved_times)})\")\n",
    "\n",
    "    plt.xlabel(\"Instances solved (sorted by runtime)\")\n",
    "    plt.ylabel(\"Runtime (s)\")\n",
    "    plt.title(\"Cactus plot: solver configurations\")\n",
    "    plt.grid(True, which='both', linestyle='--', alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        plt.show()\n",
    "    except Exception:\n",
    "        plt.savefig(RESULTS_DIR / \"cactus.png\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
